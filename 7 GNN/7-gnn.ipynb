{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Learning\n",
    "\n",
    "## Lab 7: Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn to classify nodes using a graph neural network (GNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.classification import get_accuracy_score\n",
    "from sknetwork.data import load_netset\n",
    "from sknetwork.embedding import Spectral\n",
    "from sknetwork.gnn import GNNClassifier\n",
    "from sknetwork.utils import directed2undirected\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the following datasets (see the [NetSet](https://netset.telecom-paris.fr/) collection for details):\n",
    "* Cora (directed graph + bipartite graph)\n",
    "* WikiVitals (directed graph + bipartite graph)\n",
    "\n",
    "Both datasets are graphs with node features (given by the bipartite graph) and ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = load_netset('cora')\n",
    "wikivitals = load_netset('wikivitals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embedding(embedding, labels, size=(6,6)):\n",
    "    \"\"\"Visualize embedding in 2 dimensions using TSNE. \"\"\"\n",
    "    print(\"Computing TSNE...\")\n",
    "    tsne = TSNE(random_state=8).fit_transform(embedding)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=size)\n",
    "    plt.scatter(tsne[:, 0], tsne[:, 1], c=labels, s=50, cmap='hsv')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the Cora dataset. We check the embedding of the nodes before and after learning, and the impact of the GNN architecture on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "features = dataset.biadjacency\n",
    "labels_true = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use undirected graphs\n",
    "adjacency = directed2undirected(adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Consider a GNN with a single hidden layer of dimension 16.\n",
    "\n",
    "* Run a single forward pass on the data, without learning.\n",
    "* Display the embedding provided by the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(set(labels_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GNNClassifier(dims=[hidden_dim, n_labels], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gnn.forward(adjacency, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = gnn.layers[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embedding(embedding, labels_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "We now train the GNN.\n",
    "\n",
    "* Train the GNN with 50% / 50% train / test split.\n",
    "* Give the accuracy of the classification on the train and test sets. \n",
    "* Give the total number of parameters.\n",
    "* Display the embedding provided by the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "train_ratio = 0.5\n",
    "labels = labels_true.copy()\n",
    "train_mask = np.random.random(size=len(labels)) < train_ratio\n",
    "test_mask = ~train_mask\n",
    "labels[test_mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn.fit(adjacency, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = gnn.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Retrain the GNN with an empty graph.\n",
    "* Compare the accuracy of the classification with that of the previous model. \n",
    "* Comment the results. <br>What is the learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = sparse.csr_matrix(adjacency.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "We now consider a hidden layer of dimension 32.\n",
    "\n",
    "* Retrain the GNN (with the graph).\n",
    "* Give the accuracy of the classification and the number of parameters.\n",
    "* Comment the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Finally , we take 2 hidden layers, each of dimension 16.\n",
    "\n",
    "* Retrain the GNN.\n",
    "* Give the accuracy of the classification and the number of parameters.\n",
    "* Comment the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wikivitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on Wikivitals. We take the spectral embedding of the article-word bipartite graph as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wikivitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "biadjacency = dataset.biadjacency\n",
    "names = dataset.names\n",
    "labels_true = dataset.labels\n",
    "names_labels = dataset.names_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we consider the graph as undirected\n",
    "adjacency = directed2undirected(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the spectral embedding of the bipartite graph as features\n",
    "spectral = Spectral(20)\n",
    "features = spectral.fit_transform(biadjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "We consider a GNN with a single hidden layer of dimension 16.\n",
    "* Train the GNN with 50% / 50% train / test split.\n",
    "* Give the accuracy of the classification.\n",
    "* Display the confusion matrix of the test set.\n",
    "* Give for each label the 5 articles of the test set classified with the highest confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(set(labels_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GNNClassifier(dims=[hidden_dim, n_labels], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Compare the results with those obtained with:\n",
    "* Heat diffusion on the graph.\n",
    "* Logistic regression on the features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
