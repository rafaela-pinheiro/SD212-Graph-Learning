{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Learning\n",
    "\n",
    "## Lab 7: Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn to classify nodes using a graph neural network (GNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.classification import get_accuracy_score\n",
    "from sknetwork.data import load_netset\n",
    "from sknetwork.embedding import Spectral\n",
    "from sknetwork.gnn import GNNClassifier\n",
    "from sknetwork.utils import directed2undirected\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the following datasets (see the [NetSet](https://netset.telecom-paris.fr/) collection for details):\n",
    "* Cora (directed graph + bipartite graph)\n",
    "* WikiVitals (directed graph + bipartite graph)\n",
    "\n",
    "Both datasets are graphs with node features (given by the bipartite graph) and ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = load_netset('cora')\n",
    "wikivitals = load_netset('wikivitals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embedding(embedding, labels, size=(6,6)):\n",
    "    \"\"\"Visualize embedding in 2 dimensions using TSNE. \"\"\"\n",
    "    print(\"Computing TSNE...\")\n",
    "    tsne = TSNE(random_state=8).fit_transform(embedding)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=size)\n",
    "    plt.scatter(tsne[:, 0], tsne[:, 1], c=labels, s=50, cmap='hsv')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the Cora dataset. We check the embedding of the nodes before and after learning, and the impact of the GNN architecture on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = dataset.adjacency\n",
    "features = dataset.biadjacency\n",
    "labels_true = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use undirected graphs\n",
    "adjacency = directed2undirected(adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Consider a GNN with a single hidden layer of dimension 16.\n",
    "\n",
    "* Run a single forward pass on the data, without learning.\n",
    "* Display the embedding provided by the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(set(labels_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GNNClassifier(dims=[hidden_dim, n_labels], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gnn.forward(adjacency, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = gnn.layers[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embedding(embedding, labels_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "We now train the GNN.\n",
    "\n",
    "* Train the GNN with 50% / 50% train / test split.\n",
    "* Give the accuracy of the classification on the train and test sets. \n",
    "* Give the total number of parameters.\n",
    "* Display the embedding provided by the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "train_ratio = 0.5\n",
    "labels = labels_true.copy()\n",
    "train_mask = np.random.random(size=len(labels)) < train_ratio\n",
    "test_mask = ~train_mask\n",
    "labels[test_mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn.fit(adjacency, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = gnn.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Retrain the GNN with an empty graph.\n",
    "* Compare the accuracy of the classification with that of the previous model. \n",
    "* Comment the results. <br>What is the learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = sparse.csr_matrix(adjacency.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "We now consider a hidden layer of dimension 32.\n",
    "\n",
    "* Retrain the GNN (with the graph).\n",
    "* Give the accuracy of the classification and the number of parameters.\n",
    "* Comment the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Finally , we take 2 hidden layers, each of dimension 16.\n",
    "\n",
    "* Retrain the GNN.\n",
    "* Give the accuracy of the classification and the number of parameters.\n",
    "* Comment the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wikivitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on Wikivitals. We take the spectral embedding of the article-word bipartite graph as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_WV = wikivitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_WV = dataset_WV.adjacency\n",
    "biadjacency_WV = dataset_WV.biadjacency\n",
    "names_WV = dataset_WV.names\n",
    "labels_true_WV = dataset_WV.labels\n",
    "names_labels_WV = dataset_WV.names_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we consider the graph as undirected\n",
    "adjacency_WV = directed2undirected(adjacency_WV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the spectral embedding of the bipartite graph as features\n",
    "spectral = Spectral(20)\n",
    "features_WV = spectral.fit_transform(biadjacency_WV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "We consider a GNN with a single hidden layer of dimension 16.\n",
    "* Train the GNN with 50% / 50% train / test split.\n",
    "* Give the accuracy of the classification.\n",
    "* Display the confusion matrix of the test set.\n",
    "* Give for each label the 5 articles of the test set classified with the highest confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels_WV = len(set(labels_true_WV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(labels_true_WV))\n",
    "print(np.unique(labels_true_WV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_WV = GNNClassifier(dims=[hidden_dim, n_labels_WV], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "train_ratio = 0.5\n",
    "labels_WV = labels_true_WV.copy()\n",
    "train_mask = np.random.random(size=len(labels_WV)) < train_ratio\n",
    "test_mask = ~train_mask\n",
    "labels_WV[test_mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_WV.fit(adjacency_WV, features_WV, labels_WV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_WV = gnn_WV.predict()\n",
    "\n",
    "train_acc_WV = get_accuracy_score(labels_true_WV[train_mask], labels_pred_WV[train_mask])\n",
    "test_acc_WV = get_accuracy_score(labels_true_WV[test_mask], labels_pred_WV[test_mask])\n",
    "\n",
    "print(f'WikiVitals train accuracy: {train_acc_WV:.4f}')\n",
    "print(f'WikiVitals test accuracy: {test_acc_WV:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = np.arange(len(names_labels_WV)) \n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(labels_true_WV[test_mask], labels_pred_WV[test_mask], labels=valid_labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=names_labels_WV)\n",
    "\n",
    "cm_display.plot()\n",
    "plt.xticks(rotation=90, ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probs = gnn_WV.predict_proba()\n",
    "\n",
    "for i, name in enumerate(names_labels_WV):\n",
    "\n",
    "    predicted = (labels_pred_WV[test_mask] == i)\n",
    "    if predicted.sum() > 0:\n",
    " \n",
    "        confidences = probs[test_mask][predicted, i]\n",
    "\n",
    "        article_indices = np.where(test_mask)[0][predicted]\n",
    "\n",
    "        top5_idx = np.argsort(confidences)[-5:][::-1]\n",
    "        print(f\"\\nLabel {name} - Top 5 articles:\")\n",
    "        for i, idx in enumerate(top5_idx):\n",
    "            if i < len(article_indices):\n",
    "                article_name = names_WV[article_indices[idx]]\n",
    "                confidence = confidences[idx]\n",
    "                print(f\"  {article_name}: {confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Compare the results with those obtained with:\n",
    "* Heat diffusion on the graph.\n",
    "* Logistic regression on the features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
